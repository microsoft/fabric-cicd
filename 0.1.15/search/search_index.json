{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>fabric-cicd is a Python library designed for use with Microsoft Fabric workspaces. This library supports code-first Continuous Integration / Continuous Deployment (CI/CD) automations to seamlessly integrate Source Controlled workspaces into a deployment framework. The goal is to assist CI/CD developers who prefer not to interact directly with the Microsoft Fabric APIs.</p>"},{"location":"#base-expectations","title":"Base Expectations","text":"<ul> <li>Full deployment every time, without considering commit diffs</li> <li>Deploys into the tenant of the executing identity</li> <li>Only supports items that have Source Control, and Public Create/Update APIs</li> </ul>"},{"location":"#supported-item-types","title":"Supported Item Types","text":"<ul> <li>DataPipeline</li> <li>Environment</li> <li>Notebook</li> <li>Report</li> <li>SemanticModel</li> <li>Lakehouse</li> <li>MirroredDatabase</li> <li>VariableLibrary</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install fabric-cicd, run:</p> <pre><code>pip install fabric-cicd\n</code></pre>"},{"location":"#basic-example","title":"Basic Example","text":"<pre><code>from fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id = \"your-workspace-id\",\n    repository_directory = \"your-repository-directory\",\n    item_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"],\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre>"},{"location":"about/","title":"About","text":""},{"location":"about/#support","title":"Support","text":"<p>This project uses GitHub Issues to track bugs, feature requests, and questions. Please search the existing issues before filing new issues to avoid duplicates. For new issues, file your bug, feature request, or question as a new Issue.</p>"},{"location":"about/#microsoft-support-policy","title":"Microsoft Support Policy","text":"<p>Support for this PROJECT or PRODUCT is limited to the resources listed above.</p>"},{"location":"about/#security","title":"Security","text":"<p>Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft, Azure, DotNet, AspNet and Xamarin.</p> <p>If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability, please report it to us as described below.</p>"},{"location":"about/#reporting-security-issues","title":"Reporting Security Issues","text":"<p>Please do not report security vulnerabilities through public GitHub issues.</p> <p>Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report.</p> <p>If you prefer to submit without logging in, send email to secure@microsoft.com. If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page.</p> <p>You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc.</p> <p>Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:</p> <ul> <li>Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)</li> <li>Full paths of source file(s) related to the manifestation of the issue</li> <li>The location of the affected source code (tag/branch/commit or direct URL)</li> <li>Any special configuration required to reproduce the issue</li> <li>Step-by-step instructions to reproduce the issue</li> <li>Proof-of-concept or exploit code (if possible)</li> <li>Impact of the issue, including how an attacker might exploit the issue</li> </ul> <p>This information will help us triage your report more quickly.</p> <p>If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs.</p>"},{"location":"about/#preferred-languages","title":"Preferred Languages","text":"<p>We prefer all communications to be in English.</p>"},{"location":"about/#policy","title":"Policy","text":"<p>Microsoft follows the principle of Coordinated Vulnerability Disclosure.</p>"},{"location":"about/#license","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) Microsoft Corporation.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>The following contains all major, minor, and patch version release notes.</p> <ul> <li>\ud83d\udca5 Breaking change!</li> <li>\u2728 New Functionality</li> <li>\ud83d\udd27 Bug Fix</li> <li>\ud83d\udcdd Documentation Update</li> <li>\u26a1 Internal Optimization</li> </ul>"},{"location":"changelog/#version-0115","title":"Version 0.1.15","text":"<p>Release Date: 2025-04-21</p> <ul> <li>\ud83d\udd27 Fix folders moving with every publish (#236)</li> <li>\u26a1 Introduce parallel deployments to reduce publish times (#237)</li> <li>\u26a1 Improvements to check version logic</li> <li>\ud83d\udcdd Updated Examples section in docs</li> </ul>"},{"location":"changelog/#version-0114","title":"Version 0.1.14","text":"<p>Release Date: 2025-04-09</p> <ul> <li>\u2728 Optimized &amp; beautified terminal output</li> <li>\u2728 Added changelog to output of old version check</li> <li>\ud83d\udd27 Fix workspace folder deployments in root folder (#221)</li> <li>\ud83d\udd27 Fix unpublish of workspace folders without publish (#222)</li> <li>\u26a1 Removed Colorama and Colorlog Dependency</li> </ul>"},{"location":"changelog/#version-0113","title":"Version 0.1.13","text":"<p>Release Date: 2025-04-07</p> <ul> <li>\u2728 Onboard Workspace Folders (#81)</li> <li>\u2728 Onboard Variable Library item type (#206)</li> <li>\u2728 Added support for Lakehouse Shortcuts</li> <li>\u2728 New <code>enable_environment_variable_replacement</code> feature flag (#160)</li> <li>\u26a1 User-agent now available in API headers (#207)</li> <li>\u26a1 Fixed error log typo in fabric_endpoint</li> <li>\ud83d\udd27 Fix break with invalid optional parameters (#192)</li> <li>\ud83d\udd27 Fix bug where all workspace ids were not being replaced by parameterization (#186)</li> </ul>"},{"location":"changelog/#version-0112","title":"Version 0.1.12","text":"<p>Release Date: 2025-03-27</p> <ul> <li>\ud83d\udd27 Fix constant overwrite failures (#190)</li> <li>\ud83d\udd27 Fix bug where all workspace ids were not being replaced (#186)</li> <li>\ud83d\udd27 Fix type hints for older versions of Python (#156)</li> <li>\ud83d\udd27 Fix accepted item types constant in pre-build</li> </ul>"},{"location":"changelog/#version-0111","title":"Version 0.1.11","text":"<p>Release Date: 2025-03-25</p> <ul> <li>\ud83d\udca5 Parameterization refactor introducing a new parameter file structure and parameter file validation functionality (#113)</li> <li>\ud83d\udcdd Update to parameterization docs</li> <li>\u2728 Support regex for publish exclusion (#121)</li> <li>\u2728 Override max retries via constants (#146)</li> </ul>"},{"location":"changelog/#version-0110","title":"Version 0.1.10","text":"<p>Release Date: 2025-03-19</p> <ul> <li>\u2728 DataPipeline SPN Support (#133)</li> <li>\ud83d\udd27 Workspace ID replacement in data pipelines (#164)</li> <li>\ud83d\udcdd Sample for passing in arguments from Azure DevOps Pipelines</li> </ul>"},{"location":"changelog/#version-019","title":"Version 0.1.9","text":"<p>Release Date: 2025-03-11</p> <ul> <li>\u2728 Support for Mirrored Database item type (#145)</li> <li>\u26a1 Increase reserved name wait time (#135)</li> </ul>"},{"location":"changelog/#version-018","title":"Version 0.1.8","text":"<p>Release Date: 2025-03-04</p> <ul> <li>\ud83d\udd27 Handle null byPath object in report definition file (#143)</li> <li>\ud83d\udd27 Support relative directories (#136) (#132)</li> <li>\ud83d\udd27 Increase special character support (#134)</li> <li>\u26a1 Changelog now available with version check (#127)</li> </ul>"},{"location":"changelog/#version-017","title":"Version 0.1.7","text":"<p>Release Date: 2025-02-26</p> <ul> <li>\ud83d\udd27 Fix special character support in files (#129)</li> </ul>"},{"location":"changelog/#version-016","title":"Version 0.1.6","text":"<p>Release Date: 2025-02-24</p> <ul> <li>\u2728 Onboard Lakehouse item type (#116)</li> <li>\ud83d\udcdd Update example docs (#25)</li> <li>\ud83d\udcdd Update find_replace docs (#110)</li> <li>\u26a1 Standardized docstrings to Google format</li> <li>\u26a1 Onboard file objects (#46)</li> <li>\u26a1 Leverage UpdateDefinition Flag (#28)</li> <li>\u26a1 Convert repo and workspace dictionaries (#45)</li> </ul>"},{"location":"changelog/#version-015","title":"Version 0.1.5","text":"<p>Release Date: 2025-02-18</p> <ul> <li>\ud83d\udd27 Fix Environment Failure without Public Library (#103)</li> <li>\u26a1 Introduces pytest check for PRs (#100)</li> </ul>"},{"location":"changelog/#version-014","title":"Version 0.1.4","text":"<p>Release Date: 2025-02-12</p> <ul> <li>\u2728 Support Feature Flagging (#96)</li> <li>\ud83d\udd27 Fix Image support in report deployment (#88)</li> <li>\ud83d\udd27 Fix Broken README link (#92)</li> <li>\u26a1 Workspace ID replacement improved</li> <li>\u26a1 Increased error handling in activate script</li> <li>\u26a1 Onboard pytest and coverage</li> <li>\u26a1 Improvements to nested dictionaries (#37)</li> <li>\u26a1 Support Python Installed From Windows Store (#87)</li> </ul>"},{"location":"changelog/#version-013","title":"Version 0.1.3","text":"<p>Release Date: 2025-01-29</p> <ul> <li>\u2728 Add PyPI check version to encourage version bumps (#75)</li> <li>\ud83d\udd27 Fix Semantic model initial publish results in None Url error (#61)</li> <li>\ud83d\udd27 Fix Integer parsed as float failing in handle_retry for &lt;3.12 python (#63)</li> <li>\ud83d\udd27 Fix Default item types fail to unpublish (#76)</li> <li>\ud83d\udd27 Fix Items in subfolders are skipped (#77)</li> <li>\ud83d\udcdd Update documentation &amp; examples</li> </ul>"},{"location":"changelog/#version-012","title":"Version 0.1.2","text":"<p>Release Date: 2025-01-27</p> <ul> <li>\u2728 Introduces max retry and backoff for long running / throttled calls (#27)</li> <li>\ud83d\udd27 Fix Environment publish uses arbitrary wait time (#50)</li> <li>\ud83d\udd27 Fix Environment publish doesn't wait for success (#56)</li> <li>\ud83d\udd27 Fix Long running operation steps out early for notebook publish (#58)</li> </ul>"},{"location":"changelog/#version-011","title":"Version 0.1.1","text":"<p>Release Date: 2025-01-23</p> <ul> <li>\ud83d\udd27 Fix Environment stuck in publish (#51)</li> </ul>"},{"location":"changelog/#version-010","title":"Version 0.1.0","text":"<p>Release Date: 2025-01-23</p> <ul> <li>\u2728 Initial public preview release</li> <li>\u2728 Supports Notebook, Pipeline, Semantic Model, Report, and Environment deployments</li> <li>\u2728 Supports User and System Identity authentication</li> <li>\u2728 Released to PyPi</li> <li>\u2728 Onboarded to Github Pages</li> </ul>"},{"location":"code_reference/","title":"Code Reference","text":"<p>Provides tools for managing and publishing items in a Fabric workspace.</p> <p>Classes:</p> Name Description <code>FabricWorkspace</code> <p>A class to manage and publish workspace items to the Fabric API.</p> <p>Functions:</p> Name Description <code>append_feature_flag</code> <p>Append a feature flag to the global feature_flag set.</p> <code>change_log_level</code> <p>Sets the log level for all loggers within the fabric_cicd package. Currently only supports DEBUG.</p> <code>publish_all_items</code> <p>Publishes all items defined in the <code>item_type_in_scope</code> list of the given FabricWorkspace object.</p> <code>unpublish_all_orphan_items</code> <p>Unpublishes all orphaned items not present in the repository except for those matching the exclude regex.</p>"},{"location":"code_reference/#fabric_cicd.FabricWorkspace","title":"FabricWorkspace","text":"<pre><code>FabricWorkspace(\n    workspace_id: str,\n    repository_directory: str,\n    item_type_in_scope: list[str],\n    environment: str = \"N/A\",\n    token_credential: TokenCredential = None,\n    **kwargs,\n)\n</code></pre> <p>A class to manage and publish workspace items to the Fabric API.</p> <p>Parameters:</p> Name Type Description Default <code>workspace_id</code> <code>str</code> <p>The ID of the workspace to interact with.</p> required <code>repository_directory</code> <code>str</code> <p>Local directory path of the repository where items are to be deployed from.</p> required <code>item_type_in_scope</code> <code>list[str]</code> <p>Item types that should be deployed for a given workspace.</p> required <code>environment</code> <code>str</code> <p>The environment to be used for parameterization.</p> <code>'N/A'</code> <code>token_credential</code> <code>TokenCredential</code> <p>The token credential to use for API requests.</p> <code>None</code> <code>kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"]\n... )\n</code></pre> <p>With optional parameters</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/your/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"],\n...     environment=\"your-target-environment\"\n... )\n</code></pre> <p>With token credential</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace\n&gt;&gt;&gt; from azure.identity import ClientSecretCredential\n&gt;&gt;&gt; client_id = \"your-client-id\"\n&gt;&gt;&gt; client_secret = \"your-client-secret\"\n&gt;&gt;&gt; tenant_id = \"your-tenant-id\"\n&gt;&gt;&gt; token_credential = ClientSecretCredential(\n...     client_id=client_id, client_secret=client_secret, tenant_id=tenant_id\n... )\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/your/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"],\n...     token_credential=token_credential\n... )\n</code></pre>"},{"location":"code_reference/#fabric_cicd.append_feature_flag","title":"append_feature_flag","text":"<pre><code>append_feature_flag(feature: str) -&gt; None\n</code></pre> <p>Append a feature flag to the global feature_flag set.</p> <p>Parameters:</p> Name Type Description Default <code>feature</code> <code>str</code> <p>The feature flag to be included.</p> required <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import append_feature_flag\n&gt;&gt;&gt; append_feature_flag(\"enable_lakehouse_unpublish\")\n</code></pre>"},{"location":"code_reference/#fabric_cicd.change_log_level","title":"change_log_level","text":"<pre><code>change_log_level(level: str = 'DEBUG') -&gt; None\n</code></pre> <p>Sets the log level for all loggers within the fabric_cicd package. Currently only supports DEBUG.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>str</code> <p>The logging level to set (e.g., DEBUG).</p> <code>'DEBUG'</code> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import change_log_level\n&gt;&gt;&gt; change_log_level(\"DEBUG\")\n</code></pre>"},{"location":"code_reference/#fabric_cicd.publish_all_items","title":"publish_all_items","text":"<pre><code>publish_all_items(\n    fabric_workspace_obj: FabricWorkspace,\n    item_name_exclude_regex: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Publishes all items defined in the <code>item_type_in_scope</code> list of the given FabricWorkspace object.</p> <p>Parameters:</p> Name Type Description Default <code>fabric_workspace_obj</code> <code>FabricWorkspace</code> <p>The FabricWorkspace object containing the items to be published.</p> required <code>item_name_exclude_regex</code> <code>Optional[str]</code> <p>Regex pattern to exclude specific items from being published.</p> <code>None</code> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace, publish_all_items\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"]\n... )\n&gt;&gt;&gt; publish_all_items(workspace)\n</code></pre>"},{"location":"code_reference/#fabric_cicd.unpublish_all_orphan_items","title":"unpublish_all_orphan_items","text":"<pre><code>unpublish_all_orphan_items(\n    fabric_workspace_obj: FabricWorkspace, item_name_exclude_regex: str = \"^$\"\n) -&gt; None\n</code></pre> <p>Unpublishes all orphaned items not present in the repository except for those matching the exclude regex.</p> <p>Parameters:</p> Name Type Description Default <code>fabric_workspace_obj</code> <code>FabricWorkspace</code> <p>The FabricWorkspace object containing the items to be published.</p> required <code>item_name_exclude_regex</code> <code>str</code> <p>Regex pattern to exclude specific items from being unpublished. Default is '^$' which will exclude nothing.</p> <code>'^$'</code> <p>Examples:</p> <p>Basic usage</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"]\n... )\n&gt;&gt;&gt; publish_all_items(workspace)\n&gt;&gt;&gt; unpublish_orphaned_items(workspace)\n</code></pre> <p>With regex name exclusion</p> <pre><code>&gt;&gt;&gt; from fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n&gt;&gt;&gt; workspace = FabricWorkspace(\n...     workspace_id=\"your-workspace-id\",\n...     repository_directory=\"/path/to/repo\",\n...     item_type_in_scope=[\"Environment\", \"Notebook\", \"DataPipeline\"]\n... )\n&gt;&gt;&gt; publish_all_items(workspace)\n&gt;&gt;&gt; exclude_regex = \".*_do_not_delete\"\n&gt;&gt;&gt; unpublish_orphaned_items(workspace, exclude_regex)\n</code></pre>"},{"location":"contribution/","title":"Contribution","text":"<p>This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.</p> <p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</p> <p>This project has adopted the Microsoft Open Source Code of Conduct.</p>"},{"location":"contribution/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python (version 3.10 or higher)</li> <li>PowerShell</li> <li>Azure CLI or Az.Accounts PowerShell module</li> <li>Visual Studio Code (VS Code)</li> </ul>"},{"location":"contribution/#initial-configuration","title":"Initial Configuration","text":"<ol> <li> <p>Fork the Repository on GitHub:</p> <ul> <li>Go to the repository fabric-cicd on GitHub.</li> <li>In the top right corner, click on the Fork button.</li> <li>This will create a copy of the repository in your own GitHub account.</li> </ul> </li> <li> <p>Clone Your Forked Repository:</p> <ul> <li>Once the fork is complete, go to your GitHub account and open the forked repository.</li> <li>Click on the Code button, and clone to VS Code.</li> </ul> </li> <li> <p>Run activate.ps1:</p> <ul> <li>Open the Project in VS Code</li> <li>Open PowerShell terminal</li> <li>Run activate.ps1 which will install uv, and ruff if not already found. And set up the default environment leveraging uv sync.     <pre><code>.\\activate.ps1\n</code></pre> Note that this is technically optional and is designed to work with PowerShell. You can execute these steps manually as well, this is merely a helper</li> </ul> </li> <li> <p>Select Python Interpreter:</p> <ul> <li>Open the Command Palette (Ctrl+Shift+P) and select <code>Python: Select Interpreter</code>.</li> <li>Choose the interpreter from the <code>venv</code> directory.</li> </ul> </li> <li> <p>Ensure All VS Code Extensions Are Installed:</p> <ul> <li>Open the Command Palette (Ctrl+Shift+P) and select <code>Extensions: Show Recommended Extensions</code>.</li> <li>Install all extensions recommended for the workspace.</li> </ul> </li> </ol>"},{"location":"contribution/#development","title":"Development","text":""},{"location":"contribution/#managing-dependencies","title":"Managing Dependencies","text":"<ul> <li>All dependencies in this project are managed by uv which will resolve all dependencies and lock the versions to speed up virtual environment creation.</li> <li>For additions, run:     <pre><code>uv add &lt;package-name&gt;\n</code></pre></li> <li>For removals, run:     <pre><code>uv remove &lt;package-name&gt;\n</code></pre></li> </ul>"},{"location":"contribution/#code-formatting-linting","title":"Code Formatting &amp; Linting","text":"<ul> <li>The python code within this project is maintained by ruff.</li> <li>If you install the recommended extensions, ruff will auto format on save of any file.</li> <li>Before being able to merge a PR, ruff is ran in a Github Action to ensure the files are properly formatted and maintained.</li> <li>To force linting, run the following.     <pre><code>ruff format\nruff check\n</code></pre></li> </ul>"},{"location":"example/","title":"How To","text":"<p>Welcome to the Examples section! Here you will find all necessary code samples to leverage fabric-cicd. If there is any missing information, raise a documentation issue on GitHub.</p>"},{"location":"example/#contents","title":"Contents","text":"<ul> <li>Deployment Variable Examples<ul> <li>Branch Based</li> <li>Passed Arguments</li> </ul> </li> <li>Release Pipeline Examples<ul> <li>Azure CLI</li> <li>Azure PowerShell</li> <li>Variable Groups</li> </ul> </li> <li>Authentication Examples<ul> <li>Default Credential<ul> <li>Release Pipeline Script</li> </ul> </li> <li>CLI Credential</li> <li>AZ PowerShell Credential</li> <li>Explicit SPN Secret Credential</li> </ul> </li> </ul>"},{"location":"example/authentication/","title":"Authentication Examples","text":"<p>The following are the most common authentication flows for fabric-cicd. However, because fabric-cicd supports any TokenCredential, there are multiple authentication methods available beyond the ones described here.</p>"},{"location":"example/authentication/#default-credential","title":"Default Credential","text":"<p>This approach utilizes the default credential flow, meaning no explicit TokenCredential is provided. It is the most common authentication method and is particularly useful with deployments where authentication is defined outside of this execution.</p> LocalAzure DevOpsGitHub <pre><code>'''Log in with Azure CLI (az login) or Azure PowerShell (Connect-AzAccount) prior to execution'''\n\nfrom pathlib import Path\n\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''\nLog in with Azure CLI (az login) or Azure PowerShell (Connect-AzAccount) prior to execution\nOR (Preferred) Use Az CLI or AzPowerShell ADO Tasks with a Service Connection\n'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/authentication/#release-pipeline-script","title":"Release Pipeline Script","text":"Azure DevOpsGitHub <pre><code>trigger:\n  branches:\n    include:\n      - dev\n      - main\nstages:\n  - stage: Build_Release\n    jobs:\n      - job: Build\n        pool:\n          vmImage: windows-latest\n        steps:\n          - checkout: self\n          - task: UsePythonVersion@0\n            inputs:\n              versionSpec: '3.12'\n              addToPath: true\n          - script: |\n              pip install fabric-cicd\n            displayName: 'Install fabric-cicd'\n          - task: AzureCLI@2\n            displayName: \"Deploy Fabric Workspace\"\n            inputs:\n              azureSubscription: \"HelixData-PROD\"\n              scriptType: \"ps\"\n              scriptLocation: \"inlineScript\"\n              inlineScript: |\n                python -u $(System.DefaultWorkingDirectory)/.deploy/fabric_workspace.py\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/authentication/#cli-credential","title":"CLI Credential","text":"<p>This approach utilizes the CLI credential flow, meaning it only refers to the authentication established with az login. This is agnostic of the executing user, it can be UPN, SPN, Managed Identity, etc. Whatever is used to log in will be used.</p> LocalAzure DevOpsGitHub <pre><code>'''Log in with Azure CLI (az login) prior to execution'''\n\nfrom pathlib import Path\n\nfrom azure.identity import AzureCliCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\ntoken_credential = AzureCliCredential()\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''\nLog in with Azure CLI (az login) prior to execution\nOR (Preferred) Use Az CLI ADO Tasks with a Service Connection\n'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom azure.identity import AzureCliCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\ntoken_credential = AzureCliCredential()\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/authentication/#az-powershell-credential","title":"AZ PowerShell Credential","text":"<p>This approach utilizes the AZ PowerShell credential flow, meaning it only refers to the authentication established with Connect-AzAccount. This is agnostic of the executing user, it can be UPN, SPN, Managed Identity, etc. Whatever is used to log in will be used.</p> LocalAzure DevOpsGitHub <pre><code>'''Log in with Azure PowerShell (Connect-AzAccount) prior to execution'''\n\nfrom pathlib import Path\n\nfrom azure.identity import AzurePowerShellCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\ntoken_credential = AzurePowerShellCredential()\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''\nLog in with Azure PowerShell (Connect-AzAccount) prior to execution\nOR (Preferred) Use AzPowerShell ADO Tasks with a Service Connection\n'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom azure.identity import AzurePowerShellCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\ntoken_credential = AzurePowerShellCredential()\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''\nUnconfirmed example at this time, however, the Azure DevOps example is a good starting point\n'''\n</code></pre>"},{"location":"example/authentication/#explicit-spn-secret-credential","title":"Explicit SPN Secret Credential","text":"<p>This approach utilizes directly passing in SPN Client Id and Client Secret. Although you can pass in directly, it's not recommended and should store this outside of your code. It's important to consider that SPN + Secret is still possible to leverage in the above AZ PowerShell and AZ CLI flows</p> LocalAzure DevOpsGitHub <pre><code>'''Pass the required SPN values directly into the credential object, does not require AZ PowerShell or AZ CLI'''\n\nfrom pathlib import Path\n\nfrom azure.identity import ClientSecretCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\nclient_id = \"your-client-id\"\nclient_secret = \"your-client-secret\"\ntenant_id = \"your-tenant-id\"\ntoken_credential = ClientSecretCredential(client_id=client_id, client_secret=client_secret, tenant_id=tenant_id)\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''\nPass the required SPN values directly into the credential object\nOR Store the SPN Secret in Key Vault and reference key vault in Python\nOR Store the SPN Secret in Key Vault, link key vault to ADO variable group, and reference variable group environment variable in Python\nOR (Preferred) Use AZ CLI or AZ PowerShell task and leverage Service Connection (defined above)\n\n'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom azure.identity import ClientSecretCredential\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = \"your-workspace-id\"\nenvironment = \"your-environment\"\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Use Azure CLI credential to authenticate\nclient_id = \"your-client-id\"\nclient_secret = \"your-client-secret\"\ntenant_id = \"your-tenant-id\"\ntoken_credential = ClientSecretCredential(client_id=client_id, client_secret=client_secret, tenant_id=tenant_id)\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n    token_credential=token_credential,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/deployment_variable/","title":"Deployment Variable Examples","text":"<p>A key concept in CI/CD is defining environment-specific deployment variables. The following are examples on how to inject variables from outside of the python script to handle values that are environment specific, or common accross other tooling.</p>"},{"location":"example/deployment_variable/#branch-based","title":"Branch Based","text":"<p>Leverage the following when you have specific values that you need to define per branch you are deploying from.</p> LocalAzure DevOpsGitHub <pre><code>'''Leverages Default Credential Flow for authentication. Determines variables based on locally checked out branch.'''\n\nfrom pathlib import Path\n\nimport git  # Depends on pip install gitpython\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\nrepo = git.Repo(root_directory)\nrepo.remotes.origin.pull()\nbranch = repo.active_branch.name\n\n# The defined environment values should match the names found in the parameter.yml file\nif branch == \"dev\":\n    workspace_id = \"dev-workspace-id\"\n    environment = \"DEV\"\nelif branch == \"main\":\n    workspace_id = \"prod-workspace-id\"\n    environment = \"PROD\"\nelse:\n    raise ValueError(\"Invalid branch to deploy from\")\n\n# Sample values for FabricWorkspace parameters\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Leverages Default Credential Flow for authentication. Determines variables based on the branch that originated the build.'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Assumes your script is one level down from root\nroot_directory = Path(__file__).resolve().parent\n\nbranch = os.getenv(\"BUILD_SOURCEBRANCHNAME\")\n\n# The defined environment values should match the names found in the parameter.yml file\nif branch == \"dev\":\n    workspace_id = \"dev-workspace-id\"\n    environment = \"DEV\"\nelif branch == \"main\":\n    workspace_id = \"prod-workspace-id\"\n    environment = \"PROD\"\nelse:\n    raise ValueError(\"Invalid branch to deploy from\")\n\n# Sample values for FabricWorkspace parameters\nrepository_directory = str(root_directory / \"your-workspace-directory\")\nitem_type_in_scope = [\"Notebook\", \"DataPipeline\", \"Environment\"]\n\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/deployment_variable/#passed-arguments","title":"Passed Arguments","text":"<p>Leverage the following when you want to pass in variables outside of the python script. This is most common for scenarios where you want to use one py script, but have multiple deployments.</p> LocalAzure DevOpsGitHub <pre><code>'''Leverages Default Credential Flow for authentication. Accepts parameters passed into Python during execution.'''\n\nimport argparse\n\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items\n\n# Accept parsed arguments\nparser = argparse.ArgumentParser(description='Process Azure Pipeline arguments.')\nparser.add_argument('--workspace_id', type=str)\nparser.add_argument('--environment', type=str)\nparser.add_argument('--repository_directory', type=str)\nparser.add_argument('--items_in_scope', type=str)\nargs = parser.parse_args()\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = args.workspace_id\nenvironment = args.environment\nrepository_directory = args.repository_directory\nitem_type_in_scope = args.items_in_scope.split(\",\")\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Leverages Default Credential Flow for authentication. Accepts parameters passed into Python during execution.'''\n\nimport sys\nimport os\nfrom pathlib import Path\n\nfrom fabric_cicd import FabricWorkspace, publish_all_items, unpublish_all_orphan_items, change_log_level\n\n# Force unbuffered output like `python -u`\nsys.stdout.reconfigure(line_buffering=True, write_through=True)\nsys.stderr.reconfigure(line_buffering=True, write_through=True)\n\n# Enable debugging if defined in Azure DevOps pipeline\nif os.getenv(\"SYSTEM_DEBUG\", \"false\").lower() == \"true\":\n    change_log_level(\"DEBUG\")\n\n# Accept parsed arguments\nparser = argparse.ArgumentParser(description='Process Azure Pipeline arguments.')\nparser.add_argument('--workspace_id', type=str)\nparser.add_argument('--environment', type=str)\nparser.add_argument('--repository_directory', type=str)\nparser.add_argument('--items_in_scope', type=str)\nargs = parser.parse_args()\n\n# Sample values for FabricWorkspace parameters\nworkspace_id = args.workspace_id\nenvironment = args.environment\nrepository_directory = args.repository_directory\nitem_type_in_scope = args.items_in_scope.split(\",\")\n\n# Initialize the FabricWorkspace object with the required parameters\ntarget_workspace = FabricWorkspace(\n    workspace_id=workspace_id,\n    environment=environment,\n    repository_directory=repository_directory,\n    item_type_in_scope=item_type_in_scope,\n)\n\n# Publish all items defined in item_type_in_scope\npublish_all_items(target_workspace)\n\n# Unpublish all items defined in item_type_in_scope not found in repository\nunpublish_all_orphan_items(target_workspace)\n</code></pre> <pre><code>'''Unconfirmed example at this time, however, the Azure DevOps example is a good starting point'''\n</code></pre>"},{"location":"example/release_pipeline/","title":"Release Pipeline Examples","text":"<p>The following are some common examples of how to deploy from tooling like Azure DevOps and GitHub. Note that this is not an exhaustive list, nor is it a recommendation to not use a proper Build/Release stage. These are simplified to show the potential.</p>"},{"location":"example/release_pipeline/#azure-cli","title":"Azure CLI","text":"<p>This approach will work for both the Default Credential Flow and the Azure CLI Credential Flow. However, it is recommended to use the Azure CLI Credential Flow in case there are multiple identities present in the build VM.</p> Azure DevOpsGitHub <pre><code>trigger:\n  branches:\n    include:\n      - dev\n      - main\nstages:\n  - stage: Build_Release\n    jobs:\n      - job: Build\n        pool:\n          vmImage: windows-latest\n        steps:\n          - checkout: self\n          - task: UsePythonVersion@0\n            inputs:\n              versionSpec: '3.12'\n              addToPath: true\n          - script: |\n              pip install fabric-cicd\n            displayName: 'Install fabric-cicd'\n          - task: AzureCLI@2\n            displayName: \"Deploy Fabric Workspace\"\n            inputs:\n              azureSubscription: \"your-service-connection\"\n              scriptType: \"ps\"\n              scriptLocation: \"inlineScript\"\n              inlineScript: |\n                python -u $(System.DefaultWorkingDirectory)/.deploy/fabric_workspace.py\n</code></pre> <pre><code>###Unconfirmed example at this time, however, the Azure DevOps example is a good starting point\n</code></pre>"},{"location":"example/release_pipeline/#azure-powershell","title":"Azure PowerShell","text":"<p>This approach will work for both the Default Credential Flow and the Azure PowerShell Credential Flow. However, it is recommended to use the Azure PowerShell Credential Flow in case there are multiple identities present in the build VM.</p> Azure DevOpsGitHub <pre><code>trigger:\n  branches:\n    include:\n      - dev\n      - main\nstages:\n  - stage: Build_Release\n    jobs:\n      - job: Build\n        pool:\n          vmImage: windows-latest\n        steps:\n          - checkout: self\n          - task: UsePythonVersion@0\n            inputs:\n              versionSpec: '3.12'\n              addToPath: true\n          - script: |\n              pip install fabric-cicd\n            displayName: 'Install fabric-cicd'\n          - task: AzurePowerShell@5\n            displayName: \"Deploy Fabric Workspace\"\n            inputs:\n              azureSubscription: \"your-service-connection\"\n              scriptType: \"InlineScript\"\n              scriptLocation: \"inlineScript\"\n              pwsh: true\n              Inline: |\n                python -u $(System.DefaultWorkingDirectory)/.deploy/fabric_workspace.py\n</code></pre> <pre><code>###Unconfirmed example at this time, however, the Azure DevOps example is a good starting point\n</code></pre>"},{"location":"example/release_pipeline/#variable-groups","title":"Variable Groups","text":"<p>This approach is best suited for the Passed Arguments example found in the Deployment Variable Examples, in combination with the Explicit SPN Credential flow in the Authentication Examples. The goal being to define values within the pipeline (or outside the pipeline in Azure DevOps variable groups) and inject them into the python script. Note this also doesn't take a dependency on PowerShell for those organizations or scenarios that PowerShell is not allowed.</p> Azure DevOpsGitHub <pre><code>trigger:\n  branches:\n    include:\n      - dev\n      - main\n\nparameters:\n- name: items_in_scope\n  displayName: Enter Fabric items to be deployed\n  type: string\n  default: '[\"Notebook\",\"DataPipeline\",\"Environment\"]'\n\nvariables:\n- group: Fabric_Deployment_Group_KeyVault # Linked to Azure Key Vault and contains tenant id, SPN client id, and SPN secret\n- group: Fabric_Deployment_Group  # Contains workspace_name and repository directory name\n\nstages:\n  - stage: Build_Release\n    jobs:\n      - job: Build\n        pool:\n          vmImage: windows-latest\n        steps:\n          - checkout: self\n          - task: UsePythonVersion@0\n            inputs:\n              versionSpec: '3.12'\n              addToPath: true\n          - script: |\n              pip install fabric-cicd\n            displayName: 'Install fabric-cicd'\n          - task: PythonScript@0\n            inputs:\n              scriptSource: 'filePath'\n              scriptPath: '.deploy/fabric_workspace.py'\n              arguments: |\n                --spn_client_id $(client_id) # from Fabric_Deployment_Group_KeyVault\n                --spn_client_secret $(client_secret) # from Fabric_Deployment_Group_KeyVault\n                --tenant_id $(tenant_id) # from Fabric_Deployment_Group_KeyVault\n                --workspace_id $(workspace_id) # from Fabric_Deployment_Group\n                --environment $(environment_name) # from Fabric_Deployment_Group\n                --repository_directory $repository_directory # from Fabric_Deployment_Group\n                --item_types_in_scope ${{ parameters.items_in_scope }}\n</code></pre> <pre><code>###Unconfirmed example at this time, however, the Azure DevOps example is a good starting point\n</code></pre>"},{"location":"how_to/","title":"How To","text":"<p>Welcome to the How To section! Here you will find all necessary information to leverage fabric-cicd. If there is any missing information, raise a documentation issue on GitHub.</p>"},{"location":"how_to/#contents","title":"Contents","text":"<ul> <li>Item Types<ul> <li>Data Pipelines</li> <li>Environments</li> <li>Lakehouses</li> <li>Mirrored Database</li> <li>Notebooks</li> <li>Reports</li> <li>Semantic Models</li> <li>Variable Libraries</li> </ul> </li> <li>Parameterization<ul> <li>Inputs<ul> <li><code>find_replace</code></li> <li><code>spark_pool</code></li> <li>Optional Fields</li> <li>Parameter File Validation</li> </ul> </li> <li>Sample File</li> <li>Examples<ul> <li>Notebooks</li> <li>Environments</li> </ul> </li> </ul> </li> <li>Getting Started<ul> <li>Installation</li> <li>Authentication</li> <li>Directory Structure</li> <li>GIT Flow</li> </ul> </li> <li>Optional Features<ul> <li>Feature Flags</li> <li>Debugging</li> </ul> </li> </ul>"},{"location":"how_to/getting_started/","title":"Getting Started","text":""},{"location":"how_to/getting_started/#installation","title":"Installation","text":"<p>To install fabric-cicd, run:</p> <pre><code>pip install fabric-cicd\n</code></pre>"},{"location":"how_to/getting_started/#authentication","title":"Authentication","text":"<ul> <li>You can optionally provide your own credential object that aligns with the <code>TokenCredential</code> class. For more details, see the TokenCredential documentation.</li> <li> <p>If you do not provide a <code>token_credential</code> parameter, the library will use the Azure SDK's <code>DefaultAzureCredential</code> for authentication.</p> <ul> <li>Refer to the Azure SDK documentation for the order in which credential types are attempted.</li> <li> <p>For local development with a User Principal Name (UPN), install either the Azure CLI or the Az.Accounts PowerShell module.</p> </li> <li> <p>Note: When no credential is provided, the <code>DefaultAzureCredential</code> may select an unexpected identity. For example, if you log in to the Azure CLI with a Service Principal Name (SPN) but log in to Az.Accounts with a UPN, the <code>DefaultAzureCredential</code> will prioritize the CLI authentication.</p> </li> </ul> </li> </ul>"},{"location":"how_to/getting_started/#directory-structure","title":"Directory Structure","text":"<p>This library deploys from a directory containing files and directories committed via the Fabric Source Control UI. Ensure the <code>repository_directory</code> includes only these committed items, with the exception of the <code>parameter.yml</code> file.</p> <pre><code>/&lt;your-directory&gt;\n    /&lt;item-name&gt;.&lt;item-type&gt;\n        ...\n    /&lt;item-name&gt;.&lt;item-type&gt;\n        ...\n    /&lt;workspace-subfolder&gt;\n        /&lt;item-name&gt;.&lt;item-type&gt;\n            ...\n        /&lt;item-name&gt;.&lt;item-type&gt;\n            ...\n    /parameter.yml\n</code></pre>"},{"location":"how_to/getting_started/#git-flow","title":"GIT Flow","text":"<p>The flow pictured below is the hero scenario for this library and is the recommendation if you're just starting out.</p> <ul> <li><code>Deployed</code> branches are not connected to workspaces via GIT Sync</li> <li><code>Feature</code> branches are connected to workspaces via GIT Sync</li> <li><code>Deployed</code> workspaces are only updated through script-based deployments, such as through the fabric-cicd library</li> <li><code>Feature</code> branches are created from the default branch, merged back into the default <code>Deployed</code> branch, and cherry picked into the upper <code>Deployed</code> branches</li> <li>Each deployment is a full deployment and does not consider commit diffs</li> </ul> <p></p>"},{"location":"how_to/item_types/","title":"Item Types","text":""},{"location":"how_to/item_types/#data-pipelines","title":"Data Pipelines","text":"<ul> <li>Parameterization:<ul> <li>Activities connected to items that exist in a different workspace will always point to the original item unless parameterized in the <code>find_replace</code> section of the <code>parameter.yml</code> file.</li> <li>Activities connected to items within the same workspace are re-pointed to the new item in the target workspace.</li> </ul> </li> <li>Connections are not source controlled and must be created manually.</li> <li>The executing identity of the deployment must have access to the connections, or the deployment will fail.</li> </ul>"},{"location":"how_to/item_types/#environments","title":"Environments","text":"<ul> <li>Parameterization:<ul> <li>Environments attached to custom spark pools attach to the default starter pool unless parameterized in the <code>spark_pools</code> section of the <code>parameter.yml</code> file.</li> <li>The <code>find_replace</code> section in the <code>parameter.yml</code> file is not applied to Environments.</li> </ul> </li> <li>Resources are not source controlled and will not be deployed.</li> <li>Environments with libraries will have high initial publish times (sometimes 20+ minutes).</li> </ul>"},{"location":"how_to/item_types/#lakehouses","title":"Lakehouses","text":"<ul> <li>Parameterization:<ul> <li>The <code>find_replace</code> section in the <code>parameter.yml</code> file is not applied.</li> </ul> </li> <li>Shortcut publish is disabled by default (for now), enable with feature flag <code>enable_shortcut_publish</code>.</li> <li>Schemas are not deployed unless the schema has a shortcut present.</li> <li>Unpublish is disabled by default, enable with feature flag <code>enable_lakehouse_unpublish</code>.</li> </ul>"},{"location":"how_to/item_types/#mirrored-database","title":"Mirrored Database","text":"<ul> <li>Parameterization:<ul> <li>Connections will always point to the original source database unless parameterized in the <code>find_replace</code> section of the <code>parameter.yml</code> file.</li> </ul> </li> <li>Initial deployment for Azure SQL Database or Azure SQL Managed Instance requires manual granting of System Assigned Managed Identity (SAMI) Read and Write permission to the mirrored database for replication to be successful after deployment. ref -&gt; (Prerequisites)</li> <li>Unpublish - a warning is shown for any default Semantic Models created by the Mirror Database. This is a current limitation of the Fabric API and can be ignored.</li> </ul>"},{"location":"how_to/item_types/#notebooks","title":"Notebooks","text":"<ul> <li>Parameterization:<ul> <li>Notebooks attached to lakehouses always point to the original lakehouse unless parameterized in the <code>find_replace</code> section of the <code>parameter.yml</code> file.</li> </ul> </li> <li>Resources are not source controlled and will not be deployed.</li> </ul>"},{"location":"how_to/item_types/#reports","title":"Reports","text":"<ul> <li>Parameterization:<ul> <li>Reports connected to Semantic Models outside of the same workspace always point to the original Semantic Model unless parameterized in the <code>find_replace</code> section of the <code>parameter.yml</code> file.</li> <li>Reports connected to Semantic Models within the same workspace are re-pointed to the new item in the target workspace.</li> </ul> </li> </ul>"},{"location":"how_to/item_types/#semantic-models","title":"Semantic Models","text":"<ul> <li>Parameterization:<ul> <li>Semantic Models connected to sources outside of the same workspace always point to the original item unless parameterized in the <code>find_replace</code> section of the <code>parameter.yml</code> file.</li> <li>Semantic Models connected to sources within the same workspace may or may not be re-pointed; it is best to test this before taking a dependency. Use the <code>find_replace</code> section of the <code>parameter.yml</code> file as needed.</li> </ul> </li> <li>Initial deployment requires manual configuration of the connection after deployment.</li> </ul>"},{"location":"how_to/item_types/#variable-libraries","title":"Variable Libraries","text":"<ul> <li>Parameterization:<ul> <li>The active value set of the variable library is defined by the <code>environment</code> field passed into the <code>FabricWorkspace</code> object. If no <code>environment</code> is specified, the active Value Set will not be changed.</li> </ul> </li> <li>Changing Value Sets:<ul> <li>Variable Libraries do not support programmatically changing the name of value set which is active</li> <li>After the initial deployment, if an active set is renamed, or removed, the deployment will fail</li> <li>Manual intervention will be required to make the necessary changes in the Fabric UI and then restart the deployment</li> </ul> </li> </ul>"},{"location":"how_to/optional_feature/","title":"Optional Features","text":"<p>fabric-cicd has an expected default flow; however, there will always be cases where overriding default behavior is required.</p>"},{"location":"how_to/optional_feature/#feature-flags","title":"Feature Flags","text":"<p>For scenarios that aren't supported by default, fabric-cicd offers <code>feature-flags</code>. Below is an exhaustive list of currently supported features.</p> Flag Name Description <code>enable_lakehouse_unpublish</code> Set to enable the deletion of Lakehouses <code>disable_print_identity</code> Set to disable printing the executing identity name <code>enable_shortcut_publish</code> Set to enable deploying shortcuts with the lakehouse <code>enable_environment_variable_replacement</code> Set to enable the use of pipeline variables <code>disable_workspace_folder_publish</code> Set to disable deploying workspace sub folders <p>Example</p> <pre><code>from fabric_cicd import append_feature_flag\nappend_feature_flag(\"enable_lakehouse_unpublish\")\nappend_feature_flag(\"disable_print_identity\")\nappend_feature_flag(\"enable_environment_variable_replacement\")\n</code></pre>"},{"location":"how_to/optional_feature/#debugging","title":"Debugging","text":"<p>If an error arises, or you want to have full transparency to all calls being made outside the library, enable debugging. Enabling debugging will write all API calls to the terminal and to the <code>fabric-cicd.log</code>.</p> <pre><code>from fabric_cicd import change_log_level\nchange_log_level(\"DEBUG\")\n</code></pre>"},{"location":"how_to/parameterization/","title":"Parameterization","text":"<p>To handle environment-specific values committed to git, use a <code>parameter.yml</code> file. This file supports programmatically changing values based on the <code>environment</code> field passed into the <code>FabricWorkspace</code> object. If the environment value is not found in the <code>parameter.yml</code> file, any dependent replacements will be skipped. This file should sit in the root of the <code>repository_directory</code> folder specified in the FabricWorkspace object.</p> <p>Important Notice: The <code>parameter.yml</code> file structure has been recently updated. Please refer to the documentation below for important changes. There is a grace period from March 24, 2025 to April 24, 2025 during which the old structure will still be supported, allowing users to migrate to the new structure.</p> <p>Example of parameter.yml location based on provided repository directory:</p> <pre><code>from fabric_cicd import FabricWorkspace\nworkspace = FabricWorkspace(\n    workspace_id=\"your-workspace-id\",\n    repository_directory=\"C:/dev/workspace\",\n    item_type_in_scope=[\"Notebook\"]\n)\n</code></pre> <pre><code>C:/dev/workspace\n    /HelloWorld.Notebook\n        ...\n    /GoodbyeWorld.Notebook\n        ...\n    /parameter.yml\n</code></pre> <p>Raise a feature request for additional parameterization capabilities.</p>"},{"location":"how_to/parameterization/#inputs","title":"Inputs","text":""},{"location":"how_to/parameterization/#find_replace","title":"<code>find_replace</code>","text":"<p>For generic find-and-replace operations. This will replace every instance of a specified string in every file. Specify the <code>find_value</code> and the <code>replace_value</code> for each environment (e.g., PPE, PROD). Optional fields, including <code>item_type</code>, <code>item_name</code>, and <code>file_path</code>, can be used as file filters for more fine-grained control over where the replacement occurs.</p> <p>Note: A common use case for this function is to replace connection strings, e.g., find and replace a connection GUID referenced in a data pipeline.</p> <pre><code>find_replace:\n    # Required fields: value must be a string\n    - find_value: &lt;find-this-value&gt;\n      replace_value:\n          &lt;environment-1-key&gt;: &lt;replace-with-this-value&gt;\n          &lt;environment-2-key&gt;: &lt;replace-with-this-value&gt;\n      # Optional fields: value must be a string or array of strings\n      item_type: &lt;item-type-filter-value&gt;\n      item_name: &lt;item-name-filter-value&gt;\n      file_path: &lt;file-path-filter-value&gt;\n</code></pre> <p>If the <code>enable_environment_variable_replacement</code> feature flag is set, pipeline/environment variables will be used to replace the values in the parameter.yml file with the corresponding values from the variables dictionary, see example below: Only Environment Variable beginnging with '$ENV:' will be used as replacement values.</p> <pre><code>find_replace:\n    # Lakehouse GUID\n    - find_value: \"db52be81-c2b2-4261-84fa-840c67f4bbd0\"\n      replace_value:\n        PPE: \"$ENV:ppe_lakehouse\"\n        PROD: \"$ENV:prod_lakehouse\"\n</code></pre>"},{"location":"how_to/parameterization/#spark_pool","title":"<code>spark_pool</code>","text":"<p>Environments attached to custom spark pools need to be parameterized because the <code>instance_pool_id</code> in the <code>Sparkcompute.yml</code> file isn't supported in the create/update environment APIs. Provide the <code>instance_pool_id</code> value, and the pool <code>type</code> and <code>name</code> values as the <code>replace_value</code> for each environment (e.g., PPE, PROD). An optional field, <code>item_name</code>, can be used to filter the specific environment item where the replacement will occur.</p> <pre><code>spark_pool:\n    # Required fields: value must be a string\n    - instance_pool_id: &lt;instance-pool-id-value&gt;\n      replace_value:\n          &lt;environment-1-key&gt;:\n              type: &lt;Capacity-or-Workspace&gt;\n              name: &lt;pool-name&gt;\n          &lt;environment-2-key&gt;:\n              type: &lt;Capacity-or-Workspace&gt;\n              name: &lt;pool-name&gt;\n      # Optional field: value must be a string or array of strings\n      item_name: &lt;item-name-filter-value&gt;\n</code></pre>"},{"location":"how_to/parameterization/#optional-fields","title":"Optional Fields","text":"<ul> <li>Parameterization functionality is unaffected when optional fields are omitted or left empty.</li> <li>Optional field values that are provided must match the corresponding properties in the repository file in order for the replacement to occur in the given file. If at least one filter value does not match, the replacement will be skipped for that file.</li> <li>If none of the optional fields or values are provided, the value found in any repository file is subject to replacement.</li> <li>Input values are case sensitive.</li> <li>Input values must be string or array (enables one or many values to filter on).</li> <li>YAML supports array inputs using bracket ( [ ] ) or dash ( - ) notation.</li> <li>String values should be wrapped in quotes (make sure to escape characters, such as \\ in <code>file_path</code> inputs).</li> <li>Item types must be valid; see valid types.</li> <li><code>file_path</code> accepts absolute or relative paths. Relative paths must be relative to the repository directory.</li> </ul>"},{"location":"how_to/parameterization/#parameter-file-validation","title":"Parameter File Validation","text":"<p>Validation of the <code>parameter.yml</code> file is a built-in feature of fabric-cicd, managed by the <code>Parameter</code> class. Validation is utilized in the following scenarios:</p> <p>Debuggability: Users can debug and validate their parameter file to ensure it meets the acceptable structure and input value requirements before running a deployment. Simply run the <code>debug_parameterization.py</code> script located in the <code>devtools</code> directory.</p> <p>Deployment: At the start of a deployment, an automated validation checks the validity of the <code>parameter.yml</code> file, if it is present. This step ensures that valid parameters are loaded, allowing deployment to run smoothly with correctly applied parameterized configurations. If the parameter file is invalid, the deployment will not proceed.</p>"},{"location":"how_to/parameterization/#sample-file","title":"Sample File","text":"<p>An exhaustive example of all capabilities currently supported in the <code>parameter.yml</code> file.</p> <pre><code>find_replace:\n    - find_value: \"123e4567-e89b-12d3-a456-426614174000\" # lakehouse GUID to be replaced\n      replace_value:\n          PPE: \"f47ac10b-58cc-4372-a567-0e02b2c3d479\" # PPE lakehouse GUID\n          PROD: \"9b2e5f4c-8d3a-4f1b-9c3e-2d5b6e4a7f8c\" # PROD lakehouse GUID\n      item_type: \"Notebook\" # filter on notebook files\n      item_name: [\"Hello World\", \"Goodbye World\"] # filter on specific notebook files\n      file_path:\n    - find_value: \"8f5c0cec-a8ea-48cd-9da4-871dc2642f4c\" # workspace ID to be replaced\n      replace_value:\n          PPE: \"d4e5f6a7-b8c9-4d1e-9f2a-3b4c5d6e7f8a\" # PPE workspace ID\n          PROD: \"a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d\" # PROD workspace ID\n      file_path: # filter on notebook files with these paths\n          - \"/Hello World.Notebook/notebook-content.py\"\n          - \"\\\\Goodbye World.Notebook\\\\notebook-content.py\"\n\n    # With enable_deployment_variables feature\n    - find_value: \"123e4567-e89b-12d3-a456-426614174000\" # Lakehouse GUID\n      replace_value:\n          PPE: \"f47ac10b-58cc-4372-a567-0e02b2c3d479\" # PPE lakehouse GUID\n          PROD: \"9b2e5f4c-8d3a-4f1b-9c3e-2d5b6e4a7f8c\" # PROD lakehouse GUID \n      item_type: \"Notebook\"\n      item_name: [\"Hello World\", \"Goodbye World\"]\n    - find_value: \"replace_lakehouse_id\"\n      replace_value:\n          PPE: \"$ENV:ppe_lakehouse_guid\" # environment variable replace\n          PROD: \"9b2e5f4c-8d3a-4f1b-9c3e-2d5b6e4a7f8c\"\n      item_type: \"Notebook\"\n      item_name: [\"Hello World\", \"Goodbye World\"]\n    - find_value: \"replace_lakehouse_workspace\"\n      replace_value:\n          PPE: \"$ENV:ppe_workspace_guid\" # environment variable replace\n          PROD: \"9b2e5f4c-8d3a-4f1b-9c3e-2d5b6e4a7f8c\"\n      item_type: \"Notebook\"\n      item_name: [\"Hello World\", \"Goodbye World\"]\n\nspark_pool:\n    - instance_pool_id: \"72c68dbc-0775-4d59-909d-a47896f4573b\" # spark_pool_instance_id to be replaced\n      replace_value:\n          PPE:\n              type: \"Capacity\" # target spark pool type, only supports Capacity or Workspace\n              name: \"CapacityPool_Medium\" # target spark pool name\n          PROD:\n              type: \"Capacity\" # target spark pool type, only supports Capacity or Workspace\n              name: \"CapacityPool_Large\" # target spark pool name\n      item_name: \"World\" # filter on environment file for environment named \"World\"\n    - instance_pool_id: \"e7b8f1c4-4a6e-4b8b-9b2e-8f1e5d6a9c3d\" # spark_pool_instance_id to be replaced\n      replace_value:\n          PPE:\n              type: \"Workspace\" # target spark pool type, only supports Capacity or Workspace\n              name: \"WorkspacePool_Medium\" # target spark pool name\n      item_name: [\"World_1\", \"World_2\", \"World_3\"] # filter on environment files for environments with these names\n</code></pre>"},{"location":"how_to/parameterization/#examples","title":"Examples","text":""},{"location":"how_to/parameterization/#notebooks","title":"Notebooks","text":"<p>A Notebook is attached to a Lakehouse which resides in different workspaces. The Workspace and Lakehouse GUIDs in the Notebook need to be updated to ensure the Notebook points to the correct Lakehouse once deployed.</p> <p>In the <code>notebook-content.py</code> file, the default_lakehouse <code>123e4567-e89b-12d3-a456-426614174000</code>, and default_lakehouse_workspace_id <code>8f5c0cec-a8ea-48cd-9da4-871dc2642f4c</code> must be replaced with the corresponding GUIDs of the Lakehouse in the target environment (PPE/PROD/etc).</p> <p>This replacement is managed by the <code>find_replace</code> input in the <code>parameter.yml</code> file where fabric-cicd finds every instance of the string within the specified repository files and replaces it with the string for the deployed environment.</p> <p>parameter.yml file</p> <pre><code>find_replace:\n    - find_value: \"123e4567-e89b-12d3-a456-426614174000\" # lakehouse GUID to be replaced\n      replace_value:\n          PPE: \"f47ac10b-58cc-4372-a567-0e02b2c3d479\" # PPE lakehouse GUID\n          PROD: \"9b2e5f4c-8d3a-4f1b-9c3e-2d5b6e4a7f8c\" # PROD lakehouse GUID\n      item_type: \"Notebook\" # filter on notebook files\n      item_name: [\"Hello World\", \"Goodbye World\"] # filter on specific notebook files\n      file_path:\n    - find_value: \"8f5c0cec-a8ea-48cd-9da4-871dc2642f4c\" # workspace ID to be replaced\n      replace_value:\n          PPE: \"d4e5f6a7-b8c9-4d1e-9f2a-3b4c5d6e7f8a\" # PPE workspace ID\n          PROD: \"a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d\" # PROD workspace ID\n      file_path: # filter on notebook files with these paths\n          - \"/Hello World.Notebook/notebook-content.py\"\n          - \"\\\\Goodbye World.Notebook\\\\notebook-content.py\"\n</code></pre> <p>notebook-content.py file</p> <pre><code># Fabric notebook source\n\n# METADATA ********************\n\n# META {\n# META   \"kernel_info\": {\n# META     \"name\": \"synapse_pyspark\"\n# META   },\n# META   \"dependencies\": {\n# META     \"lakehouse\": {\n# META       \"default_lakehouse\": \"123e4567-e89b-12d3-a456-426614174000\",\n# META       \"default_lakehouse_name\": \"Example_LH\",\n# META       \"default_lakehouse_workspace_id\": \"8f5c0cec-a8ea-48cd-9da4-871dc2642f4c\"\n# META     },\n# META     \"environment\": {\n# META       \"environmentId\": \"a277ea4a-e87f-8537-4ce0-39db11d4aade\",\n# META       \"workspaceId\": \"00000000-0000-0000-0000-000000000000\"\n# META     }\n# META   }\n# META }\n\n# CELL ********************\n\ndf = spark.sql(\"SELECT * FROM Example_LH.Table1 LIMIT 1000\")\ndisplay(df)\n\n# METADATA ********************\n\n# META {\n# META   \"language\": \"python\",\n# META   \"language_group\": \"synapse_pyspark\"\n# META }\n</code></pre>"},{"location":"how_to/parameterization/#environments","title":"Environments","text":"<p>An Environment is attached to a Capacity level Custom Pool. Source control for Environments does not output the right fields necessary to deploy, so the Spark Pool needs to be parameterized.</p> <p>Note: Defining different names per environment is now supported in the <code>parameter.yml</code> file.</p> <p>In the <code>Sparkcompute.yaml</code> file, the referenced instance_pool_id <code>72c68dbc-0775-4d59-909d-a47896f4573b</code> points to a capacity custom pool named <code>CapacityPool_Large</code> of pool type <code>Capacity</code> for the <code>PROD</code> environment.</p> <p>This replacement is managed by the <code>spark_pool</code> input in the <code>parameter.yml</code> file where fabric-cicd finds every instance of the <code>instance_pool_id</code> and replaces it with the pool type and pool name for the specified environment file.</p> <p>parameter.yml file</p> <pre><code>spark_pool:\n    - instance_pool_id: \"72c68dbc-0775-4d59-909d-a47896f4573b\" # spark_pool_instance_id to be replaced\n      replace_value:\n          PPE:\n              type: \"Capacity\" # target spark pool type, only supports Capacity or Workspace\n              name: \"CapacityPool_Medium\" # target spark pool name\n          PROD:\n              type: \"Capacity\" # target spark pool type, only supports Capacity or Workspace\n              name: \"CapacityPool_Large\" # target spark pool name\n      item_name: \"World\" # filter on environment file for environment named \"World\"\n</code></pre> <p>Sparkcompute.yml</p> <pre><code>enable_native_execution_engine: false\ninstance_pool_id: 72c68dbc-0775-4d59-909d-a47896f4573b\ndriver_cores: 16\ndriver_memory: 112g\nexecutor_cores: 16\nexecutor_memory: 112g\ndynamic_executor_allocation:\n    enabled: false\n    min_executors: 31\n    max_executors: 31\nruntime_version: 1.3\n</code></pre>"}]}